1 - Why do we study algorithms:

- You have to know a standard set of important algorithms from different areas of computing; 
- You should be able to design new algorithms and analyze their efficiency.

There are several ohter reasons why we study algorithms:

Efficiency: We study algorithms to find efficient solutions to problems. An efficient algorithm is one that can solve a problem with minimal time and space complexity.

Correctness: We study algorithms to ensure that they are correct and produce the desired output for all possible inputs. A correct algorithm should always produce the correct output for any given input.

Abstraction: We study algorithms to understand how to abstract a problem into a set of instructions that can be implemented on a computer.

Reusability: We study algorithms to develop reusable solutions that can be used across different applications and domains.

Optimization: We study algorithms to optimize existing solutions and develop new solutions that can solve problems in a more efficient and effective manner.

In summary, studying algorithms helps us: 
 - Understand how to solve problems efficiently and correctly, 
 - Abstract a problems into a set of instructions, 
 - Develop reusable solutions, 
 - Optimize existing solutions.


2) An algorithm is a step-by-step procedure for solving a problem or accomplishing a task. It is a finite set of instructions that take some input, perform a series of computations, and produce an output.

More strictly, an algorithm is a sequence of unambiguous instructions for solving a problem, i.e., for obtaining a required output for any legitimate input in a finite amount of time.

3) We can prove that the algorithm above stops by showing that the value of b decreases with each iteration of the while loop, and that eventually b will become zero, causing the loop to terminate.

The algorithm works by finding the greatest common divisor (GCD) of two numbers, a and b. In each iteration of the loop, the algorithm calculates the remainder of a divided by b, and assigns it to the variable b. Since the remainder is always less than b, the value of b decreases with each iteration of the loop.

Eventually, the algorithm will reach a point where the remainder of a divided by b is zero, meaning that b is a divisor of a. At this point, the loop will terminate, and the value of a, which has been progressively replaced with b during the iterations of the loop, will be the GCD of the original values of a and b.

Therefore, we can conclude that the algorithm always terminates and returns a result.

4) 