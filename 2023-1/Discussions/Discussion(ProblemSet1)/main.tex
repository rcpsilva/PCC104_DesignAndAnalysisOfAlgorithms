\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1.2in]{geometry}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}


\usepackage{tikz}
\usetikzlibrary{positioning}

\usepackage{natbib}
\usepackage{graphicx}
\usepackage{amsmath}

\title{\vspace{-2 cm}Universidade Federal de Ouro Preto \\ PCC104 - Projeto e AnÃ¡lise de Algoritmos \\ Lista 1}
\author{Prof. Rodrigo Silva}
%\date{}


\begin{document}

\maketitle

\begin{enumerate}
    \item Why do we study algorithms?
    
    \begin{itemize}
        \item You have to know a standard set of important algorithms from different areas of computing; 
        \item You should be able to design new algorithms and analyze their efficiency.
    \end{itemize}

    There are several ohter reasons why we study algorithms:
    
    \begin{itemize}

        \item Efficiency: We study algorithms to find efficient solutions to problems. An efficient algorithm is one that can solve a problem with minimal time and space complexity.
    
        \item Correctness: We study algorithms to ensure that they are correct and produce the desired output for all possible inputs. A correct algorithm should always produce the correct output for any given input.
    
        \item Abstraction: We study algorithms to understand how to abstract a problem into a set of instructions that can be implemented on a computer.
    
        \item Reusability: We study algorithms to develop reusable solutions that can be used across different applications and domains.
    
        \item Optimization: We study algorithms to optimize existing solutions and develop new solutions that can solve problems in a more efficient and effective manner.
    
    \end{itemize}
        

    In summary, studying algorithms helps us: 
    \begin{itemize}
        \item Understand how to solve problems efficiently and correctly, 
        \item Abstract a problems into a set of instructions, 
        \item Develop reusable solutions, 
        \item Optimize existing solutions.
    \end{itemize}

    
    \item  An algorithm is a step-by-step procedure for solving a problem or accomplishing a task. It is a finite set of instructions that take some input, perform a series of computations, and produce an output.
    
    More strictly, an algorithm is a sequence of unambiguous instructions for solving a problem, i.e., for obtaining a required output for any legitimate input in a finite amount of time.
    
    \item 
    
    \lstinputlisting[language=Python]{gcd.py}
    
    
    We can prove that the algorithm above stops by showing that the value of b decreases with each iteration of the while loop, and that eventually b will become zero, causing the loop to terminate.
    
    The algorithm works by finding the greatest common divisor (GCD) of two numbers, a and b. In each iteration of the loop, the algorithm calculates the remainder of a divided by b, and assigns it to the variable b. Since the remainder is always less than b, the value of b decreases with each iteration of the loop.
    
    Eventually, the algorithm will reach a point where the remainder of a divided by b is zero, meaning that b is a divisor of a. At this point, the loop will terminate, and the value of a, which has been progressively replaced with b during the iterations of the loop, will be the GCD of the original values of a and b.
    
    Therefore, we can conclude that the algorithm always terminates and returns a result.

    \item ------------
    
    \item  
    
    \begin{enumerate}
        \item Understand the problem 
        \begin{itemize}
            \item Identify what kind problem it is
            \item Solve small instances by hand 
            \item Think about scpecial cases
        \end{itemize}


        \item Define the expected capabilities of the computational device
        \begin{itemize}
            \item Is the amount of memory a concern?
            \item Is the processing capability a concern?
        \end{itemize}
    

        \item Define what kind of solution you need.
        \begin{itemize}
            \item Exact: May be too slow
            \item Approximate: Fast but may be innacurate
        \end{itemize}

        \item Select the algorithm design techinique and data structures
    
        \item Prove corectness
        
        \item Analyze the algorithm
        \begin{itemize}
            \item Time efficiency
            \item Space effiency
            \item Simplicity -> Easier to understand, easier to debug, less likely to lead to bugs.
            \item Generality
        \end{itemize}
            
        \item Code
        \begin{itemize}
            \item Programming Language
            \item Efficient implementation
        \end{itemize}
            
    \end{enumerate}
    
    \item ------------

    \item ------------

    \item ------------
    
    \item  Time complexity refers to the amount of time it takes for an algorithm to run as a function of the input size.
    Space complexity refers to the amount of memory or storage required by an algorithm as a function of the input size. 
    
    \item  The best case refers to the scenario in which an algorithm performs in the most efficient manner possible, usually when the input is already sorted or some other advantageous condition is present. For example, the best case for a sorting algorithm might occur when the input is already sorted, in which case the algorithm could complete in $O(n)$ time complexity.
    
    The worst case refers to the scenario in which an algorithm performs in the least efficient manner possible, usually when the input is in a state that is most challenging for the algorithm to handle. For example, the worst case for a sorting algorithm might occur when the input is in reverse order, in which case the algorithm could take $O(n^2)$ time complexity.
    
    The average case refers to the scenario in which an algorithm performs in a typical manner, taking into account a distribution of possible inputs. This is often more difficult to define than the best and worst cases, as it depends on the specific distribution of inputs that the algorithm will encounter in practice. For example, the average case for a sorting algorithm might be when the input is randomly ordered, in which case the algorithm might take $O(n log n)$ time complexity on average.

    \lstinputlisting[language=Python]{sequential_search.py}

\item ------------

\item ------------

\item ------------

\item 

\begin{enumerate}
    \item Big  $O$ 
    
    Formally, let $f(n)$ and $g(n)$ be two functions defined on the positive integers. We say that $f(n)$ is $O(g(n))$ if there exist positive constants $c$ and $n0$ such that for all $n \geq n0$, we have:

    $$f(n) \leq c g(n)$$
    
    In other words, f(n) is asymptotically bounded above by g(n) up to a constant factor. This is usually written as:
    
    $$f(n) = O(g(n))$$
    
    Intuitively, this means that as the input size n grows larger, the rate of growth of f(n) is no faster than the rate of growth of g(n), up to a constant factor. 
    
    It does not mean that f(n) is equal to g(n), or that f(n) is the worst-case running time of an algorithm that solves a problem of size n, but rather that f(n) is "no worse than" g(n) in terms of its growth rate.

    \item Big $\Omega$

    Big Omega notation (also called lower bound notation) is used to describe the asymptotic lower bound of a function as its input size approaches infinity. It is another way to analyze the performance of algorithms and to compare them in terms of their efficiency.

    Formally, let $f(n)$ and $g(n)$ be two functions defined on the positive integers. We say that $f(n)$ is $\Omega(g(n))$ if there exist positive constants $c$ and $n0$ such that for all $n \geq n0$, we have:

    $$f(n) \geq c g(n)$$

    In other words, $f(n)$ is asymptotically bounded below by $g(n)$ up to a constant factor. This is usually written as:

    $$f(n) = \Omega(g(n))$$

    Intuitively, this means that as the input size $n$ grows larger, the rate of growth of $f(n)$ is no slower than the rate of growth of $g(n)$, up to a constant factor. 
    
    It does not mean that $f(n)$ is equal to $g(n)$, or that $f(n)$ is the best-case running time of an algorithm that solves a problem of size $n$, but rather that $f(n)$ is "no better than" $g(n)$ in terms of its growth rate.

    \item Big $\Theta$
    
    Big Theta notation (also called tight bound notation) is used to describe the asymptotic behavior of a function when both its upper and lower bounds are the same. It is a way to precisely characterize the running time or space complexity of an algorithm.

    Formally, let $f(n)$ and $g(n)$ be two functions defined on the positive integers. We say that $f(n)$ is $\Theta(g(n))$ if there exist positive constants $c1$, $c2$, and $n0$ such that for all $n \geq n0$, we have:
    
    $$c_1 g(n) \leq f(n) \leq c_2 g(n)$$
    
    In other words, $f(n)$ is asymptotically bounded both above and below by $g(n)$ up to constant factors. This is usually written as:
    
    $$f(n) = \Theta(g(n))$$
    
    Intuitively, this means that as the input size $n$ grows larger, the rate of growth of $f(n)$ is the same as the rate of growth of $g(n)$, up to constant factors. It implies that $f(n)$ is both an upper and lower bound for the growth rate of $g(n)$. This is a precise way to describe the running time or space complexity of an algorithm, as it captures both the best and worst-case behavior.

\end{enumerate}

\item ---------------- 

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.6\textwidth]{ex_1_limit.png}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.8\textwidth]{ex_2_limit.png}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.8\textwidth]{ex_3_limit.png}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.8\textwidth]{ex_4_limit.png}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.4\textwidth]{ex_5_limit.png}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.8\textwidth]{ex_6_limit.png}
\end{figure}

\item ------------

\item ------------

\item See equation below:

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.7\textwidth]{ex_18.png}
\end{figure}

\item See equation below:

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.7\textwidth]{ex_19.png}
\end{figure}

\item ------

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.6\textwidth]{mistery.png}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics*[width=0.6\textwidth]{enigma.png}
\end{figure}

\item ------
   \begin{figure}[!ht]
        \centering
        \includegraphics*[width=0.55\textwidth]{rec1.png}
    \end{figure}
    \begin{figure}[!ht]
        \centering
        \includegraphics*[width=0.55\textwidth]{rec2.png}
    \end{figure}
    \begin{figure}[!ht]
        \centering
        \includegraphics*[width=0.7\textwidth]{rec3.png}
    \end{figure}
    \begin{figure}[!ht]
        \centering
        \includegraphics*[width=0.7\textwidth]{rec4.png}
    \end{figure}
    \begin{figure}[!ht]
        \centering
        \includegraphics*[width=0.7\textwidth]{rec5.png}
    \end{figure}


\pagebreak

Preliminaries

\begin{itemize}
    \item Arithmetic progression 
    \begin{equation*}
        a_n = a_1 + (n - 1)d
    \end{equation*}
    where
    \begin{itemize}
        \item an is the nth term in the arithmetic progression
        \item a1 is the first term in the arithmetic progression
        \item n is the number of terms in the arithmetic progression
        \item d is the common difference between consecutive terms in the arithmetic progression.
    \end{itemize}
    
    \item Sum of terms of an AP
    \begin{equation*}
        S_n = \frac{n}{2}(a_1 + a_n)
    \end{equation*}
    where
    \begin{itemize}
        \item $S_n$ is the sum of the first $n$ terms in the arithmetic progression
        \item $a_1$ is the first term in the arithmetic progression
        \item $a_n$ is the nth term in the arithmetic progression.    
    \end{itemize}

    \item Geometric progression
    \begin{equation*}
        a_n = a_1 r^{n-1}
    \end{equation*}

    \begin{itemize}
        \item $a_n$ is the nth term in the geometric progression
        \item $a_1$ is the first term in the geometric progression
        \item $n$ is the number of terms in the geometric progression
        \item $r$ is the common ratio between consecutive terms in the geometric progression.    
    \end{itemize}
    
    \item Sum of a GP
    
    \begin{equation*}
        S_n = \frac{a_1(1-r^n)}{1-r}    
    \end{equation*}
        
        where:
        
    \begin{itemize}
        \item $S_n$ is the sum of the first $n$ terms of the geometric progression
        \item $a_1$ is the first term of the geometric progression
        \item $r$ is the common ratio between consecutive terms in the geometric progression.
    \end{itemize}

\end{itemize}


\item Tracing the algorithm for n = 1 and n = 2 should help.

The recurrence for the number of key comparisons is
\begin{equation}
  C(n) = C(n-1)+1 \text{ for } n>1, C(1)=0  
\end{equation}
Solving it by backward substitutions yields $C(n)=n-1$

\item -----------
\item In fact, even some seemingly simple algorithms have proved to be very difficult to analyze with mathematical precision and certainty. As we
pointed out in Section 2.1, this is especially true for the average-case analysis.
\begin{enumerate}
    \item Understand the experiment's purpose.
    \begin{itemize}
        \item Compare different algorithms for the same problem
        \item Check the accuraccy of theoretical assertion about the algorithm's efficiency
        \item Develop an hypothesis about the algorithm efficiency class
    \end{itemize}    
    \item Decide on the efficiency metric M to be measured and the measurement unit (an operation count vs. a time unit).
    \begin{itemize}
        \item if time, get repeated measures
        \item if stochastic algorithm, get repeated measures
    \end{itemize}
    \item Decide on characteristics of the input sample (its range, size (random or uniform?), and so on).
    \item Prepare a program implementing the algorithm (or algorithms) for the experimentation.
    \item Generate a sample of inputs.
    \item Run the algorithm (or algorithms) on the sample's inputs and record the data observed.
    \item Analyze the data obtained.
\end{enumerate}


\end{enumerate}

\end{document}

